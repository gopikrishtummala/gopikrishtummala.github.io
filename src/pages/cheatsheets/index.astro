---
import Main from "@/layouts/Main.astro";
import Layout from "@/layouts/Layout.astro";
import Header from "@/components/Header.astro";
import Footer from "@/components/Footer.astro";
import Mindmap from "@/components/Mindmap.astro";
import { SITE } from "@/config";

// Cheatsheet data - all 14 chapters
const cheatsheets = [
  {
    id: "intro-to-ml",
    title: "Intro to ML",
    description: "Motivation, applications, types of learning, history, and ML pipeline",
  },
  {
    id: "data-evaluation",
    title: "Data & Evaluation",
    description: "Data preprocessing, train/val/test splits, cross-validation, and evaluation metrics",
  },
  {
    id: "classical-supervised",
    title: "Classical Supervised Learning",
    description: "Linear models, regularization, decision trees, and k-NN",
  },
  {
    id: "stats-learning-theory",
    title: "Stats & Learning Theory",
    description: "Generalization bounds, VC dimension, bias-variance, and PAC learning",
  },
  {
    id: "advanced-classical",
    title: "Advanced Classical Models",
    description: "Support Vector Machines and Bayesian methods",
  },
  {
    id: "ensemble-methods",
    title: "Ensemble Methods",
    description: "Bagging, Random Forests, Boosting, and modern implementations",
  },
  {
    id: "tree-based-ml",
    title: "Tree-Based Machine Learning",
    description: "A comprehensive overview of decision trees, ensemble methods, and boosting algorithms",
  },
  {
    id: "optimization-ml",
    title: "Optimization for ML",
    description: "Gradient descent variants, advanced optimizers, learning rate strategies",
  },
  {
    id: "modern-deep-learning",
    title: "Modern Deep Learning",
    description: "Neural networks, activations, training, architectures, and representation learning",
  },
  {
    id: "unsupervised-learning",
    title: "Unsupervised Learning",
    description: "Clustering, dimensionality reduction, and generative models",
  },
  {
    id: "probabilistic-graphical",
    title: "Probabilistic & Graphical Models",
    description: "Mixture models, EM algorithm, Markov models, and Bayesian networks",
  },
  {
    id: "modern-topics",
    title: "Modern Topics / Extensions",
    description: "Self-supervised learning, meta-learning, federated learning, RL, and continual learning",
  },
  {
    id: "interpretability-fairness",
    title: "Interpretability & Fairness",
    description: "Interpretability methods, SHAP, fairness definitions, and responsible AI",
  },
  {
    id: "scaling-production",
    title: "Scaling & Production ML",
    description: "Large-scale training, hyperparameter tuning, MLOps, and AutoML",
  },
  {
    id: "project-research-skills",
    title: "Project & Research Skills",
    description: "Problem formulation, experiment design, model selection, and research mindset",
  },
];

// Mindmap data for all chapters
const introToMLData = {
  root: "ðŸ”¹ Intro to ML",
  children: [
    {
      label: "Motivation & Applications",
      children: [
        {
          label: "Why ML?",
          children: [
            { label: "Rules-based systems fail on complex data" },
            { label: "Data is abundant & cheap" },
            { label: "Human expertise is scarce/expensive" },
          ],
        },
        {
          label: "Killer Apps",
          children: [
            { label: "Computer Vision" },
            { label: "NLP / LLMs" },
            { label: "Recommenders" },
            { label: "Healthcare, Finance, Robotics" },
          ],
        },
      ],
    },
    {
      label: "Types of Learning",
      children: [
        {
          label: "Supervised",
          children: [
            { label: "Labeled data" },
            { label: "Regression (continuous)" },
            { label: "Classification (discrete)" },
          ],
        },
        {
          label: "Unsupervised",
          children: [{ label: "No labels â†’ discover patterns" }],
        },
        {
          label: "Reinforcement",
          children: [{ label: "Agent + environment + rewards" }],
        },
        {
          label: "Semi-/Self-supervised",
          children: [{ label: "Leverage unlabeled data heavily" }],
        },
      ],
    },
    {
      label: "History & Milestones",
      children: [
        { label: "1950sâ€“60s: Perceptron, early neural nets" },
        { label: "1980s: Backpropagation" },
        { label: "1990s: SVMs, Boosting" },
        { label: "2010s: Deep Learning revolution (AlexNet â†’ Transformers)" },
        { label: "2020s: Foundation models, multimodal, agents" },
      ],
    },
    {
      label: "ML Pipeline (End-to-End)",
      children: [
        { label: "Problem â†’ Data â†’ Features â†’ Model â†’ Eval â†’ Deploy â†’ Monitor" },
      ],
    },
    {
      label: "Biasâ€“Variance & Generalization",
      children: [
        { label: "Bias: Underfitting (high training error)" },
        { label: "Variance: Overfitting (low training, high test error)" },
        { label: "Decomposition: Error = BiasÂ² + Variance + Noise" },
        { label: "Goal: Minimize test error (generalization)" },
      ],
    },
  ],
};

const dataEvaluationData = {
  root: "ðŸ”¹ Data & Evaluation",
  children: [
    {
      label: "Data Preprocessing",
      children: [
        {
          label: "Cleaning",
          children: [
            { label: "Missing values (impute / drop)" },
            { label: "Outliers" },
          ],
        },
        {
          label: "Scaling",
          children: [
            { label: "Min-Max, Standard, Robust, Quantile" },
          ],
        },
        {
          label: "Encoding",
          children: [
            { label: "One-hot, Label, Target, Embeddings" },
          ],
        },
      ],
    },
    {
      label: "Train/Val/Test Split",
      children: [
        { label: "Simple 70/15/15 or 80/10/10" },
        { label: "Stratified (for imbalance)" },
        { label: "Time-series / Group splits" },
      ],
    },
    {
      label: "Cross-Validation",
      children: [
        { label: "k-Fold, Stratified k-Fold" },
        { label: "Leave-One-Out, Repeated CV" },
        { label: "Nested CV (hyperparam tuning)" },
      ],
    },
    {
      label: "Evaluation Metrics",
      children: [
        {
          label: "Classification",
          children: [
            { label: "Accuracy, Precision, Recall, F1" },
            { label: "ROC-AUC, PR-AUC" },
            { label: "Confusion matrix, Calibration" },
          ],
        },
        {
          label: "Regression",
          children: [
            { label: "MSE, RMSE, MAE, RÂ², Adjusted RÂ²" },
          ],
        },
        {
          label: "Ranking / Retrieval",
          children: [
            { label: "NDCG, MAP, MRR" },
          ],
        },
        {
          label: "Imbalanced / Real-world",
          children: [
            { label: "FÎ², Cohen's Kappa, Matthews Corr." },
          ],
        },
      ],
    },
  ],
};

const classicalSupervisedData = {
  root: "ðŸ”¹ Classical Supervised Learning",
  children: [
    {
      label: "Linear Models",
      children: [
        {
          label: "Linear Regression",
          children: [
            { label: "Closed form: (Xáµ€X)â»Â¹Xáµ€y" },
            { label: "Assumptions (linearity, homoscedasticity, independence)" },
          ],
        },
        {
          label: "Logistic Regression",
          children: [
            { label: "Sigmoid + Cross-entropy" },
            { label: "Multiclass: Softmax" },
          ],
        },
      ],
    },
    {
      label: "Regularization",
      children: [
        { label: "L2 (Ridge) â†’ shrinks coefficients" },
        { label: "L1 (Lasso) â†’ sparsity / feature selection" },
        { label: "Elastic Net (L1 + L2)" },
      ],
    },
    {
      label: "Decision Trees",
      children: [
        { label: "Splitting: Gini / Entropy / MSE" },
        { label: "Pruning: Cost-complexity, Reduced-error" },
        { label: "Pros: Interpretable, non-linear" },
        { label: "Cons: Unstable, greedy" },
      ],
    },
    {
      label: "k-Nearest Neighbors",
      children: [
        { label: "Distance metrics: Euclidean, Manhattan, Cosine" },
        { label: "Curse of dimensionality" },
        { label: "Weighted KNN, Approximate NN (FAISS, HNSW)" },
      ],
    },
  ],
};

const statsLearningTheoryData = {
  root: "ðŸ”¹ Stats & Learning Theory",
  children: [
    {
      label: "Generalization Bounds",
      children: [
        { label: "Hoeffding / Chernoff" },
        { label: "Uniform convergence" },
      ],
    },
    {
      label: "VC Dimension",
      children: [
        { label: "Shattering" },
        { label: "Linear classifiers: VC = d+1" },
        { label: "Sample complexity â‰ˆ VC / ÎµÂ²" },
      ],
    },
    {
      label: "Bias-Variance Decomposition",
      children: [
        { label: "E[(y âˆ’ Å·)Â²] = BiasÂ² + Var + ÏƒÂ²" },
      ],
    },
    {
      label: "PAC Learning",
      children: [
        { label: "Probably Approximately Correct" },
        { label: "Agnostic PAC, Realizable case" },
      ],
    },
    {
      label: "Other Key Ideas",
      children: [
        { label: "No Free Lunch Theorem" },
        { label: "Occam's Razor" },
        { label: "Double Descent (modern view)" },
      ],
    },
  ],
};

const advancedClassicalData = {
  root: "ðŸ”¹ Advanced Classical Models",
  children: [
    {
      label: "Support Vector Machines",
      children: [
        { label: "Max-margin hyperplane" },
        { label: "Soft-margin (slack + C)" },
        {
          label: "Kernel Trick",
          children: [
            { label: "RBF: exp(âˆ’Î³â€–xâˆ’xâ€²â€–Â²)" },
            { label: "Polynomial, Sigmoid" },
          ],
        },
      ],
    },
    {
      label: "Bayesian Methods",
      children: [
        {
          label: "Bayes Rule",
          children: [
            { label: "P(Î¸|D) âˆ P(D|Î¸)P(Î¸)" },
          ],
        },
        {
          label: "Naive Bayes",
          children: [
            { label: "Gaussian, Multinomial, Bernoulli" },
          ],
        },
        {
          label: "Bayesian Networks",
          children: [
            { label: "DAG + CPDs" },
            { label: "Exact inference (variable elimination)" },
            { label: "Approximate (MCMC, variational)" },
          ],
        },
      ],
    },
  ],
};

const ensembleMethodsData = {
  root: "ðŸ”¹ Ensemble Methods",
  children: [
    {
      label: "Bagging",
      children: [
        { label: "Bootstrap + aggregate" },
        { label: "Reduces variance" },
      ],
    },
    {
      label: "Random Forests",
      children: [
        { label: "Bagging + random feature subsets" },
        { label: "OOB error, feature importance" },
      ],
    },
    {
      label: "Boosting",
      children: [
        { label: "AdaBoost (exponential loss, weights)" },
        { label: "Gradient Boosting (fit residuals)" },
      ],
    },
    {
      label: "Modern Boosting (Industry Standard)",
      children: [
        { label: "XGBoost (regularized, approx splits, DART)" },
        { label: "LightGBM (histogram, leaf-wise, GOSS)" },
        { label: "CatBoost (ordered boosting, native categoricals)" },
      ],
    },
  ],
};

// Tree-Based ML data (existing)
const treeBasedMLData = {
  root: "Tree-Based Machine Learning",
  children: [
    {
      label: "Decision Trees",
      children: [
        {
          label: "Structure",
          children: [
            { label: "Root Node" },
            { label: "Internal Nodes" },
            { label: "Leaf Nodes" },
            { label: "Depth / Height" },
          ],
        },
        {
          label: "Types",
          children: [
            { label: "Classification Tree" },
            { label: "Regression Tree" },
          ],
        },
        {
          label: "Splitting Criteria",
          children: [
            {
              label: "Classification",
              children: [
                { label: "Gini Impurity" },
                { label: "Entropy" },
                { label: "Information Gain" },
              ],
            },
            {
              label: "Regression",
              children: [
                { label: "MSE" },
                { label: "MAE" },
                { label: "Variance Reduction" },
              ],
            },
          ],
        },
        {
          label: "Stopping Criteria",
          children: [
            { label: "Max Depth" },
            { label: "Min Samples Split" },
            { label: "Min Samples Leaf" },
            { label: "Pure Node" },
          ],
        },
        {
          label: "Pruning",
          children: [
            { label: "Pre-pruning" },
            { label: "Post-pruning" },
          ],
        },
        {
          label: "Issues",
          children: [
            { label: "Overfitting" },
            { label: "High Variance" },
            { label: "Sensitive to Noise" },
          ],
        },
      ],
    },
    {
      label: "Bias-Variance Tradeoff",
      children: [
        { label: "Deep Tree -> Low Bias High Variance" },
        { label: "Shallow Tree -> High Bias Low Variance" },
        { label: "Ensembles Reduce Variance" },
      ],
    },
    {
      label: "Ensemble Methods",
      children: [
        {
          label: "Bagging",
          children: [
            { label: "Bootstrap Sampling" },
            { label: "Parallel Training" },
            { label: "Majority Vote / Averaging" },
            { label: "Reduces Variance" },
          ],
        },
        {
          label: "Random Forest",
          children: [
            { label: "Bagging + Feature Randomness" },
            { label: "Random Feature Subset per Split" },
            { label: "OOB Error" },
            { label: "Feature Importance" },
          ],
        },
        {
          label: "Extra Trees",
          children: [
            { label: "Random Thresholds" },
            { label: "More Randomness" },
            { label: "Lower Variance" },
          ],
        },
      ],
    },
    {
      label: "Boosting",
      children: [
        {
          label: "Core Idea",
          children: [
            { label: "Sequential Learning" },
            { label: "Focus on Errors" },
            { label: "Weak Learners" },
          ],
        },
        {
          label: "AdaBoost",
          children: [
            { label: "Reweight Samples" },
            { label: "Weighted Voting" },
          ],
        },
        {
          label: "Gradient Boosting",
          children: [
            { label: "Fit Residuals" },
            { label: "Gradient Descent in Function Space" },
            { label: "Learning Rate" },
            { label: "Additive Model" },
          ],
        },
        {
          label: "Regularization",
          children: [
            { label: "Learning Rate" },
            { label: "Number of Trees" },
            { label: "Max Depth" },
            { label: "Subsampling" },
          ],
        },
        {
          label: "XGBoost",
          children: [
            { label: "Regularized Objective" },
            { label: "Tree Pruning" },
            { label: "Second-order Gradients" },
            { label: "Missing Value Handling" },
          ],
        },
        {
          label: "LightGBM",
          children: [
            { label: "Leaf-wise Growth" },
            { label: "Histogram Splitting" },
            { label: "GOSS Sampling" },
          ],
        },
        {
          label: "CatBoost",
          children: [
            { label: "Native Categorical Handling" },
            { label: "Ordered Boosting" },
            { label: "Target Leakage Reduction" },
          ],
        },
      ],
    },
    {
      label: "Interpretability",
      children: [
        {
          label: "Feature Importance",
          children: [
            { label: "Impurity-based" },
            { label: "Permutation Importance" },
          ],
        },
        { label: "SHAP Values" },
        { label: "Partial Dependence Plots" },
        { label: "Decision Path Visualization" },
      ],
    },
    {
      label: "Practical Considerations",
      children: [
        { label: "No Feature Scaling Needed" },
        { label: "Handles Mixed Data Types" },
        { label: "Strong for Tabular Data" },
        { label: "Poor Extrapolation" },
        { label: "Memory Heavy for Large Forests" },
      ],
    },
    {
      label: "Complexity",
      children: [
        { label: "Tree ~ O(n log n)" },
        { label: "Boosting Sequential Slower" },
        { label: "Random Forest Parallelizable" },
      ],
    },
  ],
};

const optimizationMLData = {
  root: "ðŸ”¹ Optimization for ML",
  children: [
    {
      label: "Gradient Descent Variants",
      children: [
        { label: "Batch GD" },
        { label: "SGD (noisy but fast)" },
        { label: "Mini-batch (sweet spot)" },
      ],
    },
    {
      label: "Advanced Optimizers",
      children: [
        { label: "Momentum" },
        { label: "RMSProp / AdaGrad" },
        { label: "Adam (Î²1=0.9, Î²2=0.999)" },
        { label: "AdamW, Lion, Sophia (2024â€“25)" },
      ],
    },
    {
      label: "Learning Rate Strategies",
      children: [
        { label: "Step decay, Exponential, Cosine" },
        { label: "Warmup + decay (common in transformers)" },
        { label: "One-cycle policy" },
      ],
    },
    {
      label: "Convex vs Non-Convex",
      children: [
        { label: "Convex â†’ global optimum" },
        { label: "Non-convex â†’ local minima, saddles, plateaus" },
      ],
    },
    {
      label: "Second-Order Methods",
      children: [
        { label: "Newton, Quasi-Newton (BFGS, L-BFGS)" },
        { label: "Limited by scale" },
      ],
    },
  ],
};

const modernDeepLearningData = {
  root: "ðŸ”¹ Modern Deep Learning",
  children: [
    {
      label: "Neural Networks Basics",
      children: [
        { label: "Perceptron â†’ MLP" },
        { label: "Universal approximation" },
      ],
    },
    {
      label: "Activation Functions",
      children: [
        { label: "ReLU family (ReLU, Leaky, GELU, Swish)" },
        { label: "Avoid vanishing gradients" },
      ],
    },
    {
      label: "Training",
      children: [
        { label: "Backpropagation + Chain rule" },
        { label: "Initialization (He, Xavier)" },
        { label: "Batch Norm / Layer Norm / Group Norm" },
      ],
    },
    {
      label: "Architectures",
      children: [
        { label: "CNNs (ResNet, EfficientNet, ConvNeXt)" },
        { label: "RNNs â†’ LSTMs/GRUs" },
        { label: "Transformers (Self-attention, Multi-head, Positional encoding)" },
      ],
    },
    {
      label: "Representation Learning",
      children: [
        { label: "Embeddings (Word2Vec â†’ BERT â†’ modern LLMs)" },
        { label: "Contrastive learning (SimCLR, CLIP)" },
      ],
    },
  ],
};

const unsupervisedLearningData = {
  root: "ðŸ”¹ Unsupervised Learning",
  children: [
    {
      label: "Clustering",
      children: [
        { label: "k-Means (Lloyd's, elbow, silhouette)" },
        { label: "Hierarchical (agglomerative + dendrogram)" },
        { label: "DBSCAN (density-based)" },
        { label: "GMM (soft clustering)" },
      ],
    },
    {
      label: "Dimensionality Reduction",
      children: [
        { label: "PCA (linear, variance-max)" },
        { label: "t-SNE (perplexity, KL divergence)" },
        { label: "UMAP (faster, better topology preservation)" },
      ],
    },
    {
      label: "Generative Models",
      children: [
        { label: "Autoencoders (undercomplete, denoising, VAE)" },
        { label: "GANs (minimax, modern variants like StyleGAN, Diffusion)" },
      ],
    },
  ],
};

const probabilisticGraphicalData = {
  root: "ðŸ”¹ Probabilistic & Graphical Models",
  children: [
    {
      label: "Mixture Models & EM",
      children: [
        { label: "Gaussian Mixture Models" },
        { label: "EM Algorithm (E-step: responsibilities, M-step: MLE)" },
      ],
    },
    {
      label: "Markov Models",
      children: [
        { label: "HMMs (Forward-Backward, Viterbi)" },
        { label: "Markov Random Fields" },
      ],
    },
    {
      label: "Bayesian Networks",
      children: [
        { label: "Structure learning" },
        { label: "Inference (exact vs approximate)" },
      ],
    },
    {
      label: "Modern Connections",
      children: [
        { label: "Probabilistic programming (Pyro, NumPyro)" },
        { label: "Diffusion models as hierarchical latents" },
      ],
    },
  ],
};

const modernTopicsData = {
  root: "ðŸ”¹ Modern Topics / Extensions",
  children: [
    {
      label: "Self-Supervised Learning",
      children: [
        { label: "Contrastive (SimCLR, MoCo)" },
        { label: "Masked modeling (BERT, MAE)" },
        { label: "BYOL, SimSiam, DINO" },
      ],
    },
    {
      label: "Meta-Learning",
      children: [
        { label: "Few-shot: MAML, Reptile, ProtoNets" },
        { label: "Optimization-based vs metric-based" },
      ],
    },
    {
      label: "Federated Learning",
      children: [
        { label: "FedAvg, FedProx" },
        { label: "Privacy (differential privacy, secure aggregation)" },
      ],
    },
    {
      label: "Reinforcement Learning",
      children: [
        { label: "MDPs, Q-Learning, Policy Gradients" },
        { label: "Modern: PPO, SAC, Dreamer, AlphaFold-style" },
      ],
    },
    {
      label: "Continual / Lifelong Learning",
      children: [
        { label: "Catastrophic forgetting" },
        { label: "Replay buffers, EWC, GEM" },
      ],
    },
  ],
};

const interpretabilityFairnessData = {
  root: "ðŸ”¹ Interpretability & Fairness",
  children: [
    {
      label: "Interpretability Toolbox",
      children: [
        { label: "Intrinsic: Decision trees, linear models" },
        { label: "Post-hoc: Feature importance, Partial Dependence Plots" },
      ],
    },
    {
      label: "Model-Agnostic Methods",
      children: [
        { label: "LIME (local surrogate)" },
        { label: "SHAP (Shapley values, KernelSHAP, TreeSHAP)" },
      ],
    },
    {
      label: "Fairness",
      children: [
        {
          label: "Definitions",
          children: [
            { label: "Demographic Parity" },
            { label: "Equalized Odds" },
            { label: "Equal Opportunity" },
          ],
        },
        {
          label: "Mitigation",
          children: [
            { label: "Pre-processing, In-processing, Post-processing" },
          ],
        },
      ],
    },
    {
      label: "Responsible AI",
      children: [
        { label: "Bias detection, Adversarial debiasing, Explainable AI regulations" },
      ],
    },
  ],
};

const scalingProductionData = {
  root: "ðŸ”¹ Scaling & Production ML",
  children: [
    {
      label: "Large-Scale Training",
      children: [
        { label: "Data parallelism, Model parallelism, Pipeline" },
        { label: "ZeRO, FSDP, DeepSpeed, Megatron" },
      ],
    },
    {
      label: "Hyperparameter Tuning",
      children: [
        { label: "Grid / Random search" },
        { label: "Bayesian optimization (Optuna, Hyperopt)" },
        { label: "Neural Architecture Search (DARTS, NAS)" },
      ],
    },
    {
      label: "MLOps / Production",
      children: [
        { label: "Experiment tracking (MLflow, Weights & Biases)" },
        { label: "Model serving (TorchServe, TF Serving, vLLM)" },
        { label: "Monitoring (data drift, concept drift, performance)" },
        { label: "Feature stores (Feast, Tecton)" },
      ],
    },
    {
      label: "AutoML",
      children: [
        { label: "Full pipelines: Auto-sklearn, H2O, Google AutoML" },
        { label: "Modern: LLM-powered (e.g., AutoGPT-style agents)" },
      ],
    },
  ],
};

const projectResearchSkillsData = {
  root: "ðŸ”¹ Project & Research Skills",
  children: [
    {
      label: "Problem Formulation",
      children: [
        { label: "Define task, success metric, baseline" },
        { label: "Literature review (arXiv, PapersWithCode)" },
      ],
    },
    {
      label: "Experiment Design",
      children: [
        { label: "Ablation studies" },
        { label: "Statistical significance (t-tests, bootstrap)" },
        { label: "Reproducibility (seeds, Docker, Hydra)" },
      ],
    },
    {
      label: "Model Selection & Deployment",
      children: [
        { label: "Tradeoffs: accuracy vs latency vs cost" },
        { label: "A/B testing, Canary releases" },
      ],
    },
    {
      label: "Research Mindset",
      children: [
        { label: "Reproducibility crisis awareness" },
        { label: "Ethics & societal impact" },
        { label: "Open-source contribution" },
        { label: "Writing papers, blogging, presenting" },
      ],
    },
  ],
};

// Map cheatsheet IDs to their data
const mindmapDataMap: Record<string, any> = {
  "intro-to-ml": introToMLData,
  "data-evaluation": dataEvaluationData,
  "classical-supervised": classicalSupervisedData,
  "stats-learning-theory": statsLearningTheoryData,
  "advanced-classical": advancedClassicalData,
  "ensemble-methods": ensembleMethodsData,
  "tree-based-ml": treeBasedMLData,
  "optimization-ml": optimizationMLData,
  "modern-deep-learning": modernDeepLearningData,
  "unsupervised-learning": unsupervisedLearningData,
  "probabilistic-graphical": probabilisticGraphicalData,
  "modern-topics": modernTopicsData,
  "interpretability-fairness": interpretabilityFairnessData,
  "scaling-production": scalingProductionData,
  "project-research-skills": projectResearchSkillsData,
};
---

<Layout title={`ML Cheatsheets | ${SITE.title}`}>
  <Header />
  <Main pageTitle="ML Cheatsheets" pageDesc="Visual mindmaps for machine learning concepts - Complete ML course coverage">
    <div class="space-y-12">
      <!-- Navigation for cheatsheets -->
      <div class="grid gap-4 sm:grid-cols-2 lg:grid-cols-3">
        {cheatsheets.map((cheatsheet) => (
          <a
            href={`#${cheatsheet.id}`}
            class="group relative overflow-hidden rounded-2xl border border-white/40 bg-white/70 p-6 shadow-lg backdrop-blur-sm transition-all hover:border-accent/60 hover:shadow-xl hover:-translate-y-1 dark:border-slate-700/40 dark:bg-slate-900/70"
          >
            <div class="absolute inset-0 -z-10 bg-gradient-to-br from-accent/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100" />
            <h2 class="text-xl font-semibold text-foreground group-hover:text-accent transition-colors">
              {cheatsheet.title}
            </h2>
            <p class="mt-2 text-sm text-secondary-foreground">
              {cheatsheet.description}
            </p>
          </a>
        ))}
      </div>

      <!-- All Cheatsheet Sections -->
      {cheatsheets.map((cheatsheet) => (
        <section id={cheatsheet.id} class="scroll-mt-24">
          <div class="mb-6">
            <h2 class="text-2xl font-semibold text-foreground">
              {cheatsheet.title}
            </h2>
            <p class="mt-2 text-sm text-secondary-foreground">
              {cheatsheet.description}
            </p>
          </div>
          <div class="overflow-x-auto rounded-2xl border border-white/40 bg-white/50 p-6 shadow-lg backdrop-blur-sm dark:border-slate-700/40 dark:bg-slate-900/50">
            <Mindmap data={mindmapDataMap[cheatsheet.id]} />
          </div>
        </section>
      ))}
    </div>
  </Main>
  <Footer />
</Layout>
