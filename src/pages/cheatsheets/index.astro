---
import Main from "@/layouts/Main.astro";
import Layout from "@/layouts/Layout.astro";
import Header from "@/components/Header.astro";
import Footer from "@/components/Footer.astro";
import Mindmap from "@/components/Mindmap.astro";
import { SITE } from "@/config";

// Cheatsheet data - all 14 chapters
const cheatsheets = [
  {
    id: "intro-to-ml",
    title: "Intro to ML",
    description: "Motivation, applications, types of learning, history, and ML pipeline",
  },
  {
    id: "data-evaluation",
    title: "Data & Evaluation",
    description: "Data preprocessing, train/val/test splits, cross-validation, and evaluation metrics",
  },
  {
    id: "classical-supervised",
    title: "Classical Supervised Learning",
    description: "Linear models, regularization, decision trees, and k-NN",
  },
  {
    id: "stats-learning-theory",
    title: "Stats & Learning Theory",
    description: "Generalization bounds, VC dimension, bias-variance, and PAC learning",
  },
  {
    id: "advanced-classical",
    title: "Advanced Classical Models",
    description: "Support Vector Machines and Bayesian methods",
  },
  {
    id: "ensemble-methods",
    title: "Ensemble Methods",
    description: "Bagging, Random Forests, Boosting, and modern implementations",
  },
  {
    id: "tree-based-ml",
    title: "Tree-Based Machine Learning",
    description: "A comprehensive overview of decision trees, ensemble methods, and boosting algorithms",
  },
  {
    id: "optimization-ml",
    title: "Optimization for ML",
    description: "Gradient descent variants, advanced optimizers, learning rate strategies",
  },
  {
    id: "modern-deep-learning",
    title: "Modern Deep Learning",
    description: "Neural networks, activations, training, architectures, and representation learning",
  },
  {
    id: "unsupervised-learning",
    title: "Unsupervised Learning",
    description: "Clustering, dimensionality reduction, and generative models",
  },
  {
    id: "probabilistic-graphical",
    title: "Probabilistic & Graphical Models",
    description: "Mixture models, EM algorithm, Markov models, and Bayesian networks",
  },
  {
    id: "modern-topics",
    title: "Modern Topics / Extensions",
    description: "Self-supervised learning, meta-learning, federated learning, RL, and continual learning",
  },
  {
    id: "interpretability-fairness",
    title: "Interpretability & Fairness",
    description: "Interpretability methods, SHAP, fairness definitions, and responsible AI",
  },
  {
    id: "scaling-production",
    title: "Scaling & Production ML",
    description: "Large-scale training, hyperparameter tuning, MLOps, and AutoML",
  },
  {
    id: "project-research-skills",
    title: "Project & Research Skills",
    description: "Problem formulation, experiment design, model selection, and research mindset",
  },
  {
    id: "computer-vision",
    title: "Computer Vision",
    description: "Classical image processing, deep learning architectures, detection/segmentation, generative models, 3D vision, and multimodal learning",
  },
  {
    id: "python-interview",
    title: "Python Interview",
    description: "Advanced patterns, data structures, algorithms, and tricky gotchas for technical interviews",
  },
];

// Mindmap data for all chapters
const introToMLData = {
  root: "ðŸ”¹ Intro to ML",
  children: [
    {
      label: "Motivation & Applications",
      children: [
        {
          label: "Why ML?",
          children: [
            { label: "Rules-based systems fail on complex data" },
            { label: "Data is abundant & cheap" },
            { label: "Human expertise is scarce/expensive" },
          ],
        },
        {
          label: "Killer Apps",
          children: [
            { label: "Computer Vision" },
            { label: "NLP / LLMs" },
            { label: "Recommenders" },
            { label: "Healthcare, Finance, Robotics" },
          ],
        },
      ],
    },
    {
      label: "Types of Learning",
      children: [
        {
          label: "Supervised",
          children: [
            { label: "Labeled data" },
            { label: "Regression (continuous)" },
            { label: "Classification (discrete)" },
          ],
        },
        {
          label: "Unsupervised",
          children: [{ label: "No labels â†’ discover patterns" }],
        },
        {
          label: "Reinforcement",
          children: [{ label: "Agent + environment + rewards" }],
        },
        {
          label: "Semi-/Self-supervised",
          children: [{ label: "Leverage unlabeled data heavily" }],
        },
      ],
    },
    {
      label: "History & Milestones",
      children: [
        { label: "1950sâ€“60s: Perceptron, early neural nets" },
        { label: "1980s: Backpropagation" },
        { label: "1990s: SVMs, Boosting" },
        { label: "2010s: Deep Learning revolution (AlexNet â†’ Transformers)" },
        { label: "2020s: Foundation models, multimodal, agents" },
      ],
    },
    {
      label: "ML Pipeline (End-to-End)",
      children: [
        { label: "Problem â†’ Data â†’ Features â†’ Model â†’ Eval â†’ Deploy â†’ Monitor" },
      ],
    },
    {
      label: "Biasâ€“Variance & Generalization",
      children: [
        { label: "Bias: Underfitting (high training error)" },
        { label: "Variance: Overfitting (low training, high test error)" },
        { label: "Decomposition: Error = BiasÂ² + Variance + Noise" },
        { label: "Goal: Minimize test error (generalization)" },
      ],
    },
  ],
};

const dataEvaluationData = {
  root: "ðŸ”¹ Data & Evaluation",
  children: [
    {
      label: "Data Preprocessing",
      children: [
        {
          label: "Cleaning",
          children: [
            { label: "Missing values (impute / drop)" },
            { label: "Outliers" },
          ],
        },
        {
          label: "Scaling",
          children: [
            { label: "Min-Max, Standard, Robust, Quantile" },
          ],
        },
        {
          label: "Encoding",
          children: [
            { label: "One-hot, Label, Target, Embeddings" },
          ],
        },
      ],
    },
    {
      label: "Train/Val/Test Split",
      children: [
        { label: "Simple 70/15/15 or 80/10/10" },
        { label: "Stratified (for imbalance)" },
        { label: "Time-series / Group splits" },
      ],
    },
    {
      label: "Cross-Validation",
      children: [
        { label: "k-Fold, Stratified k-Fold" },
        { label: "Leave-One-Out, Repeated CV" },
        { label: "Nested CV (hyperparam tuning)" },
      ],
    },
    {
      label: "Evaluation Metrics",
      children: [
        {
          label: "Classification",
          children: [
            { label: "Accuracy, Precision, Recall, F1" },
            { label: "ROC-AUC, PR-AUC" },
            { label: "Confusion matrix, Calibration" },
          ],
        },
        {
          label: "Regression",
          children: [
            { label: "MSE, RMSE, MAE, RÂ², Adjusted RÂ²" },
          ],
        },
        {
          label: "Ranking / Retrieval",
          children: [
            { label: "NDCG, MAP, MRR" },
          ],
        },
        {
          label: "Imbalanced / Real-world",
          children: [
            { label: "FÎ², Cohen's Kappa, Matthews Corr." },
          ],
        },
      ],
    },
  ],
};

const classicalSupervisedData = {
  root: "ðŸ”¹ Classical Supervised Learning",
  children: [
    {
      label: "Linear Models",
      children: [
        {
          label: "Linear Regression",
          children: [
            { label: "Closed form: (Xáµ€X)â»Â¹Xáµ€y" },
            { label: "Assumptions (linearity, homoscedasticity, independence)" },
          ],
        },
        {
          label: "Logistic Regression",
          children: [
            { label: "Sigmoid + Cross-entropy" },
            { label: "Multiclass: Softmax" },
          ],
        },
      ],
    },
    {
      label: "Regularization",
      children: [
        { label: "L2 (Ridge) â†’ shrinks coefficients" },
        { label: "L1 (Lasso) â†’ sparsity / feature selection" },
        { label: "Elastic Net (L1 + L2)" },
      ],
    },
    {
      label: "Decision Trees",
      children: [
        { label: "Splitting: Gini / Entropy / MSE" },
        { label: "Pruning: Cost-complexity, Reduced-error" },
        { label: "Pros: Interpretable, non-linear" },
        { label: "Cons: Unstable, greedy" },
      ],
    },
    {
      label: "k-Nearest Neighbors",
      children: [
        { label: "Distance metrics: Euclidean, Manhattan, Cosine" },
        { label: "Curse of dimensionality" },
        { label: "Weighted KNN, Approximate NN (FAISS, HNSW)" },
      ],
    },
  ],
};

const statsLearningTheoryData = {
  root: "ðŸ”¹ Stats & Learning Theory",
  children: [
    {
      label: "Generalization Bounds",
      children: [
        { label: "Hoeffding / Chernoff" },
        { label: "Uniform convergence" },
      ],
    },
    {
      label: "VC Dimension",
      children: [
        { label: "Shattering" },
        { label: "Linear classifiers: VC = d+1" },
        { label: "Sample complexity â‰ˆ VC / ÎµÂ²" },
      ],
    },
    {
      label: "Bias-Variance Decomposition",
      children: [
        { label: "E[(y âˆ’ Å·)Â²] = BiasÂ² + Var + ÏƒÂ²" },
      ],
    },
    {
      label: "PAC Learning",
      children: [
        { label: "Probably Approximately Correct" },
        { label: "Agnostic PAC, Realizable case" },
      ],
    },
    {
      label: "Other Key Ideas",
      children: [
        { label: "No Free Lunch Theorem" },
        { label: "Occam's Razor" },
        { label: "Double Descent (modern view)" },
      ],
    },
  ],
};

const advancedClassicalData = {
  root: "ðŸ”¹ Advanced Classical Models",
  children: [
    {
      label: "Support Vector Machines",
      children: [
        { label: "Max-margin hyperplane" },
        { label: "Soft-margin (slack + C)" },
        {
          label: "Kernel Trick",
          children: [
            { label: "RBF: exp(âˆ’Î³â€–xâˆ’xâ€²â€–Â²)" },
            { label: "Polynomial, Sigmoid" },
          ],
        },
      ],
    },
    {
      label: "Bayesian Methods",
      children: [
        {
          label: "Bayes Rule",
          children: [
            { label: "P(Î¸|D) âˆ P(D|Î¸)P(Î¸)" },
          ],
        },
        {
          label: "Naive Bayes",
          children: [
            { label: "Gaussian, Multinomial, Bernoulli" },
          ],
        },
        {
          label: "Bayesian Networks",
          children: [
            { label: "DAG + CPDs" },
            { label: "Exact inference (variable elimination)" },
            { label: "Approximate (MCMC, variational)" },
          ],
        },
      ],
    },
  ],
};

const ensembleMethodsData = {
  root: "ðŸ”¹ Ensemble Methods",
  children: [
    {
      label: "Bagging",
      children: [
        { label: "Bootstrap + aggregate" },
        { label: "Reduces variance" },
      ],
    },
    {
      label: "Random Forests",
      children: [
        { label: "Bagging + random feature subsets" },
        { label: "OOB error, feature importance" },
      ],
    },
    {
      label: "Boosting",
      children: [
        { label: "AdaBoost (exponential loss, weights)" },
        { label: "Gradient Boosting (fit residuals)" },
      ],
    },
    {
      label: "Modern Boosting (Industry Standard)",
      children: [
        { label: "XGBoost (regularized, approx splits, DART)" },
        { label: "LightGBM (histogram, leaf-wise, GOSS)" },
        { label: "CatBoost (ordered boosting, native categoricals)" },
      ],
    },
  ],
};

// Tree-Based ML data (existing)
const treeBasedMLData = {
  root: "Tree-Based Machine Learning",
  children: [
    {
      label: "Decision Trees",
      children: [
        {
          label: "Structure",
          children: [
            { label: "Root Node" },
            { label: "Internal Nodes" },
            { label: "Leaf Nodes" },
            { label: "Depth / Height" },
          ],
        },
        {
          label: "Types",
          children: [
            { label: "Classification Tree" },
            { label: "Regression Tree" },
          ],
        },
        {
          label: "Splitting Criteria",
          children: [
            {
              label: "Classification",
              children: [
                { label: "Gini Impurity" },
                { label: "Entropy" },
                { label: "Information Gain" },
              ],
            },
            {
              label: "Regression",
              children: [
                { label: "MSE" },
                { label: "MAE" },
                { label: "Variance Reduction" },
              ],
            },
          ],
        },
        {
          label: "Stopping Criteria",
          children: [
            { label: "Max Depth" },
            { label: "Min Samples Split" },
            { label: "Min Samples Leaf" },
            { label: "Pure Node" },
          ],
        },
        {
          label: "Pruning",
          children: [
            { label: "Pre-pruning" },
            { label: "Post-pruning" },
          ],
        },
        {
          label: "Issues",
          children: [
            { label: "Overfitting" },
            { label: "High Variance" },
            { label: "Sensitive to Noise" },
          ],
        },
      ],
    },
    {
      label: "Bias-Variance Tradeoff",
      children: [
        { label: "Deep Tree -> Low Bias High Variance" },
        { label: "Shallow Tree -> High Bias Low Variance" },
        { label: "Ensembles Reduce Variance" },
      ],
    },
    {
      label: "Ensemble Methods",
      children: [
        {
          label: "Bagging",
          children: [
            { label: "Bootstrap Sampling" },
            { label: "Parallel Training" },
            { label: "Majority Vote / Averaging" },
            { label: "Reduces Variance" },
          ],
        },
        {
          label: "Random Forest",
          children: [
            { label: "Bagging + Feature Randomness" },
            { label: "Random Feature Subset per Split" },
            { label: "OOB Error" },
            { label: "Feature Importance" },
          ],
        },
        {
          label: "Extra Trees",
          children: [
            { label: "Random Thresholds" },
            { label: "More Randomness" },
            { label: "Lower Variance" },
          ],
        },
      ],
    },
    {
      label: "Boosting",
      children: [
        {
          label: "Core Idea",
          children: [
            { label: "Sequential Learning" },
            { label: "Focus on Errors" },
            { label: "Weak Learners" },
          ],
        },
        {
          label: "AdaBoost",
          children: [
            { label: "Reweight Samples" },
            { label: "Weighted Voting" },
          ],
        },
        {
          label: "Gradient Boosting",
          children: [
            { label: "Fit Residuals" },
            { label: "Gradient Descent in Function Space" },
            { label: "Learning Rate" },
            { label: "Additive Model" },
          ],
        },
        {
          label: "Regularization",
          children: [
            { label: "Learning Rate" },
            { label: "Number of Trees" },
            { label: "Max Depth" },
            { label: "Subsampling" },
          ],
        },
        {
          label: "XGBoost",
          children: [
            { label: "Regularized Objective" },
            { label: "Tree Pruning" },
            { label: "Second-order Gradients" },
            { label: "Missing Value Handling" },
          ],
        },
        {
          label: "LightGBM",
          children: [
            { label: "Leaf-wise Growth" },
            { label: "Histogram Splitting" },
            { label: "GOSS Sampling" },
          ],
        },
        {
          label: "CatBoost",
          children: [
            { label: "Native Categorical Handling" },
            { label: "Ordered Boosting" },
            { label: "Target Leakage Reduction" },
          ],
        },
      ],
    },
    {
      label: "Interpretability",
      children: [
        {
          label: "Feature Importance",
          children: [
            { label: "Impurity-based" },
            { label: "Permutation Importance" },
          ],
        },
        { label: "SHAP Values" },
        { label: "Partial Dependence Plots" },
        { label: "Decision Path Visualization" },
      ],
    },
    {
      label: "Practical Considerations",
      children: [
        { label: "No Feature Scaling Needed" },
        { label: "Handles Mixed Data Types" },
        { label: "Strong for Tabular Data" },
        { label: "Poor Extrapolation" },
        { label: "Memory Heavy for Large Forests" },
      ],
    },
    {
      label: "Complexity",
      children: [
        { label: "Tree ~ O(n log n)" },
        { label: "Boosting Sequential Slower" },
        { label: "Random Forest Parallelizable" },
      ],
    },
  ],
};

const optimizationMLData = {
  root: "ðŸ”¹ Optimization for ML",
  children: [
    {
      label: "Gradient Descent Variants",
      children: [
        { label: "Batch GD" },
        { label: "SGD (noisy but fast)" },
        { label: "Mini-batch (sweet spot)" },
      ],
    },
    {
      label: "Advanced Optimizers",
      children: [
        { label: "Momentum" },
        { label: "RMSProp / AdaGrad" },
        { label: "Adam (Î²1=0.9, Î²2=0.999)" },
        { label: "AdamW, Lion, Sophia (2024â€“25)" },
      ],
    },
    {
      label: "Learning Rate Strategies",
      children: [
        { label: "Step decay, Exponential, Cosine" },
        { label: "Warmup + decay (common in transformers)" },
        { label: "One-cycle policy" },
      ],
    },
    {
      label: "Convex vs Non-Convex",
      children: [
        { label: "Convex â†’ global optimum" },
        { label: "Non-convex â†’ local minima, saddles, plateaus" },
      ],
    },
    {
      label: "Second-Order Methods",
      children: [
        { label: "Newton, Quasi-Newton (BFGS, L-BFGS)" },
        { label: "Limited by scale" },
      ],
    },
  ],
};

const modernDeepLearningData = {
  root: "ðŸ”¹ Modern Deep Learning",
  children: [
    {
      label: "Neural Networks Basics",
      children: [
        { label: "Perceptron â†’ MLP" },
        { label: "Universal approximation" },
      ],
    },
    {
      label: "Activation Functions",
      children: [
        { label: "ReLU family (ReLU, Leaky, GELU, Swish)" },
        { label: "Avoid vanishing gradients" },
      ],
    },
    {
      label: "Training",
      children: [
        { label: "Backpropagation + Chain rule" },
        { label: "Initialization (He, Xavier)" },
        { label: "Batch Norm / Layer Norm / Group Norm" },
      ],
    },
    {
      label: "Architectures",
      children: [
        { label: "CNNs (ResNet, EfficientNet, ConvNeXt)" },
        { label: "RNNs â†’ LSTMs/GRUs" },
        { label: "Transformers (Self-attention, Multi-head, Positional encoding)" },
      ],
    },
    {
      label: "Representation Learning",
      children: [
        { label: "Embeddings (Word2Vec â†’ BERT â†’ modern LLMs)" },
        { label: "Contrastive learning (SimCLR, CLIP)" },
      ],
    },
  ],
};

const unsupervisedLearningData = {
  root: "ðŸ”¹ Unsupervised Learning",
  children: [
    {
      label: "Clustering",
      children: [
        { label: "k-Means (Lloyd's, elbow, silhouette)" },
        { label: "Hierarchical (agglomerative + dendrogram)" },
        { label: "DBSCAN (density-based)" },
        { label: "GMM (soft clustering)" },
      ],
    },
    {
      label: "Dimensionality Reduction",
      children: [
        { label: "PCA (linear, variance-max)" },
        { label: "t-SNE (perplexity, KL divergence)" },
        { label: "UMAP (faster, better topology preservation)" },
      ],
    },
    {
      label: "Generative Models",
      children: [
        { label: "Autoencoders (undercomplete, denoising, VAE)" },
        { label: "GANs (minimax, modern variants like StyleGAN, Diffusion)" },
      ],
    },
  ],
};

const probabilisticGraphicalData = {
  root: "ðŸ”¹ Probabilistic & Graphical Models",
  children: [
    {
      label: "Mixture Models & EM",
      children: [
        { label: "Gaussian Mixture Models" },
        { label: "EM Algorithm (E-step: responsibilities, M-step: MLE)" },
      ],
    },
    {
      label: "Markov Models",
      children: [
        { label: "HMMs (Forward-Backward, Viterbi)" },
        { label: "Markov Random Fields" },
      ],
    },
    {
      label: "Bayesian Networks",
      children: [
        { label: "Structure learning" },
        { label: "Inference (exact vs approximate)" },
      ],
    },
    {
      label: "Modern Connections",
      children: [
        { label: "Probabilistic programming (Pyro, NumPyro)" },
        { label: "Diffusion models as hierarchical latents" },
      ],
    },
  ],
};

const modernTopicsData = {
  root: "ðŸ”¹ Modern Topics / Extensions",
  children: [
    {
      label: "Self-Supervised Learning",
      children: [
        { label: "Contrastive (SimCLR, MoCo)" },
        { label: "Masked modeling (BERT, MAE)" },
        { label: "BYOL, SimSiam, DINO" },
      ],
    },
    {
      label: "Meta-Learning",
      children: [
        { label: "Few-shot: MAML, Reptile, ProtoNets" },
        { label: "Optimization-based vs metric-based" },
      ],
    },
    {
      label: "Federated Learning",
      children: [
        { label: "FedAvg, FedProx" },
        { label: "Privacy (differential privacy, secure aggregation)" },
      ],
    },
    {
      label: "Reinforcement Learning",
      children: [
        { label: "MDPs, Q-Learning, Policy Gradients" },
        { label: "Modern: PPO, SAC, Dreamer, AlphaFold-style" },
      ],
    },
    {
      label: "Continual / Lifelong Learning",
      children: [
        { label: "Catastrophic forgetting" },
        { label: "Replay buffers, EWC, GEM" },
      ],
    },
  ],
};

const interpretabilityFairnessData = {
  root: "ðŸ”¹ Interpretability & Fairness",
  children: [
    {
      label: "Interpretability Toolbox",
      children: [
        { label: "Intrinsic: Decision trees, linear models" },
        { label: "Post-hoc: Feature importance, Partial Dependence Plots" },
      ],
    },
    {
      label: "Model-Agnostic Methods",
      children: [
        { label: "LIME (local surrogate)" },
        { label: "SHAP (Shapley values, KernelSHAP, TreeSHAP)" },
      ],
    },
    {
      label: "Fairness",
      children: [
        {
          label: "Definitions",
          children: [
            { label: "Demographic Parity" },
            { label: "Equalized Odds" },
            { label: "Equal Opportunity" },
          ],
        },
        {
          label: "Mitigation",
          children: [
            { label: "Pre-processing, In-processing, Post-processing" },
          ],
        },
      ],
    },
    {
      label: "Responsible AI",
      children: [
        { label: "Bias detection, Adversarial debiasing, Explainable AI regulations" },
      ],
    },
  ],
};

const scalingProductionData = {
  root: "ðŸ”¹ Scaling & Production ML",
  children: [
    {
      label: "Large-Scale Training",
      children: [
        { label: "Data parallelism, Model parallelism, Pipeline" },
        { label: "ZeRO, FSDP, DeepSpeed, Megatron" },
      ],
    },
    {
      label: "Hyperparameter Tuning",
      children: [
        { label: "Grid / Random search" },
        { label: "Bayesian optimization (Optuna, Hyperopt)" },
        { label: "Neural Architecture Search (DARTS, NAS)" },
      ],
    },
    {
      label: "MLOps / Production",
      children: [
        { label: "Experiment tracking (MLflow, Weights & Biases)" },
        { label: "Model serving (TorchServe, TF Serving, vLLM)" },
        { label: "Monitoring (data drift, concept drift, performance)" },
        { label: "Feature stores (Feast, Tecton)" },
      ],
    },
    {
      label: "AutoML",
      children: [
        { label: "Full pipelines: Auto-sklearn, H2O, Google AutoML" },
        { label: "Modern: LLM-powered (e.g., AutoGPT-style agents)" },
      ],
    },
  ],
};

const projectResearchSkillsData = {
  root: "ðŸ”¹ Project & Research Skills",
  children: [
    {
      label: "Problem Formulation",
      children: [
        { label: "Define task, success metric, baseline" },
        { label: "Literature review (arXiv, PapersWithCode)" },
      ],
    },
    {
      label: "Experiment Design",
      children: [
        { label: "Ablation studies" },
        { label: "Statistical significance (t-tests, bootstrap)" },
        { label: "Reproducibility (seeds, Docker, Hydra)" },
      ],
    },
    {
      label: "Model Selection & Deployment",
      children: [
        { label: "Tradeoffs: accuracy vs latency vs cost" },
        { label: "A/B testing, Canary releases" },
      ],
    },
    {
      label: "Research Mindset",
      children: [
        { label: "Reproducibility crisis awareness" },
        { label: "Ethics & societal impact" },
        { label: "Open-source contribution" },
        { label: "Writing papers, blogging, presenting" },
      ],
    },
  ],
};

const computerVisionData = {
  root: "ðŸ”¹ Computer Vision",
  children: [
    {
      label: "Classical Image Processing & Frequency",
      children: [
        {
          label: "Spatial Filters vs. Frequency Domain",
          children: [
            {
              label: "Spatial Domain",
              children: [
                { label: "Convolution using kernels directly on pixels" },
                { label: "Gaussian: smoothing/blurring" },
                { label: "Sobel: edge detection" },
              ],
            },
            {
              label: "Frequency Domain (2D Fourier Transform)",
              children: [
                { label: "Converts image: spatial â†’ spatial frequency" },
                { label: "High frequencies: edges/noise" },
                { label: "Low frequencies: smooth areas" },
              ],
            },
            {
              label: "Convolution Theorem",
              children: [
                { label: "Convolution in spatial domain" },
                { label: "= Element-wise multiplication in frequency domain" },
              ],
            },
          ],
        },
        {
          label: "Image Restoration",
          children: [
            {
              label: "Inverse Filter",
              children: [
                { label: "Recovers blurred image" },
                { label: "Catastrophically amplifies noise" },
              ],
            },
            {
              label: "Wiener Filter",
              children: [
                { label: "Optimal tradeoff" },
                { label: "Minimizes MSE between estimated & true image" },
                { label: "Accounts for degradation function & noise power spectra" },
              ],
            },
          ],
        },
        {
          label: "Feature Matching (Classic)",
          children: [
            {
              label: "Detectors (e.g., Harris Corner)",
              children: [
                { label: "Find interest points" },
                { label: "Invariant to rotation/translation" },
              ],
            },
            {
              label: "Descriptors (e.g., SIFT)",
              children: [
                { label: "Describe patch around keypoint" },
                { label: "Invariant to scale & illumination" },
              ],
            },
            {
              label: "Bag of Visual Words (BoW)",
              children: [
                { label: "Cluster descriptors via k-means" },
                { label: "Create 'visual vocabulary'" },
                { label: "Represent image as histogram of 'words'" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Core Deep Learning Architectures",
      children: [
        {
          label: "Convolutional Neural Networks (CNNs)",
          children: [
            {
              label: "Key Properties",
              children: [
                { label: "Weight sharing" },
                { label: "Local connectivity" },
                { label: "Translation invariance/equivariance" },
              ],
            },
            {
              label: "Receptive Field",
              children: [
                { label: "Region of input image" },
                { label: "Affects specific feature map in deeper layers" },
              ],
            },
          ],
        },
        {
          label: "Vision Transformers (ViTs)",
          children: [
            { label: "Divide images into non-overlapping patches" },
            { label: "Flatten patches" },
            { label: "Apply linear projections + positional embeddings" },
            {
              label: "Self-Attention Equation",
              children: [
                { label: "Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V" },
              ],
            },
            {
              label: "Tradeoff",
              children: [
                { label: "Lacks CNN inductive biases (translation invariance)" },
                { label: "Requires larger datasets to train from scratch" },
                { label: "Scales better to massive data" },
              ],
            },
          ],
        },
        {
          label: "Explainability",
          children: [
            {
              label: "Grad-CAM",
              children: [
                { label: "Uses gradients of target concept" },
                { label: "Flows into final convolutional layer" },
                { label: "Produces coarse localization map" },
                { label: "Highlights important regions for prediction" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Key Vision Tasks: Detection, Segmentation, Video",
      children: [
        {
          label: "Object Detection Architectures",
          children: [
            {
              label: "Two-Stage (Faster R-CNN)",
              children: [
                { label: "Stage 1: Generate region proposals (RPN)" },
                { label: "Stage 2: Classify & refine bounding boxes" },
                { label: "High accuracy, slower inference" },
              ],
            },
            {
              label: "Single-Stage (YOLO, SSD)",
              children: [
                { label: "Frames detection as single regression problem" },
                { label: "Over dense spatial grid" },
                { label: "Faster, better for real-time" },
                { label: "Historically struggled with tiny objects" },
              ],
            },
          ],
        },
        {
          label: "Image Segmentation Paradigms",
          children: [
            {
              label: "Semantic Segmentation",
              children: [
                { label: "Classifies every pixel into category" },
                { label: "e.g., 'car', 'road'" },
                { label: "Does not distinguish between different cars" },
              ],
            },
            {
              label: "Instance Segmentation",
              children: [
                { label: "Identifies & delineates each distinct object" },
                { label: "e.g., 'Car 1', 'Car 2'" },
              ],
            },
            {
              label: "Panoptic Segmentation",
              children: [
                { label: "Unifies semantic & instance" },
                { label: "Segments distinct objects ('things')" },
                { label: "Segments amorphous background ('stuff')" },
              ],
            },
          ],
        },
        {
          label: "Tracking & Video",
          children: [
            {
              label: "Optical Flow (Lucas-Kanade)",
              children: [
                { label: "Estimates pixel motion between frames" },
                { label: "Based on brightness constancy assumption" },
                { label: "Pixel intensities don't change between frames" },
                { label: "Spatial smoothness constraint" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Generative Models",
      children: [
        {
          label: "Variational Autoencoders (VAEs)",
          children: [
            { label: "Learn continuous latent space" },
            {
              label: "Optimized by maximizing ELBO",
              children: [
                { label: "Evidence Lower Bound" },
                { label: "Balances reconstruction loss" },
                { label: "KL-divergence term forces latent to match prior (Gaussian)" },
              ],
            },
          ],
        },
        {
          label: "Generative Adversarial Networks (GANs)",
          children: [
            { label: "Minimax game" },
            { label: "Generator tries to fool Discriminator" },
            { label: "Known for sharp images" },
            {
              label: "Challenges",
              children: [
                { label: "Training instability" },
                { label: "Mode collapse (limited variety of outputs)" },
              ],
            },
          ],
        },
        {
          label: "Diffusion Models",
          children: [
            {
              label: "Forward Process",
              children: [
                { label: "Gradually adds Gaussian noise" },
                { label: "Over T steps" },
              ],
            },
            {
              label: "Reverse Process",
              children: [
                { label: "Neural network (often U-Net) learns to denoise" },
                { label: "Step-by-step recovery of data" },
              ],
            },
            {
              label: "Advantages",
              children: [
                { label: "Beats GANs in diversity" },
                { label: "Better stability" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "3D Vision & Geometry",
      children: [
        {
          label: "Camera Models & Coordinates",
          children: [
            {
              label: "Homogeneous Coordinates",
              children: [
                { label: "2D points: [x, y, 1]" },
                { label: "3D points: [X, Y, Z, 1]" },
                { label: "Allows translation & perspective projection" },
                { label: "Represented as matrix multiplications" },
              ],
            },
          ],
        },
        {
          label: "Epipolar Geometry",
          children: [
            { label: "Relates two views of same 3D scene" },
            {
              label: "Fundamental Matrix (F)",
              children: [
                { label: "Algebraic representation of epipolar geometry" },
                { label: "If x and x' are corresponding points" },
                { label: "They satisfy: x'^T F x = 0" },
              ],
            },
            {
              label: "Triangulation",
              children: [
                { label: "Using camera projection matrices" },
                { label: "Matching 2D points across multiple views" },
                { label: "Calculate 3D depth of point" },
              ],
            },
          ],
        },
        {
          label: "Bird's Eye View (BEV) Transformation",
          children: [
            { label: "Project 2D camera features â†’ 3D/BEV grid" },
            { label: "Depth estimation or transformer cross-attention" },
            { label: "BEVFormer: transformer-based approach" },
            { label: "Foundational for multi-camera systems" },
            { label: "Critical for trajectory planning" },
          ],
        },
        {
          label: "Sensor Fusion",
          children: [
            {
              label: "Sensor Types",
              children: [
                { label: "Cameras: dense, rich semantics, no depth" },
                { label: "LiDAR: sparse, accurate depth, no color" },
                { label: "Radar: velocity tracking, weather resistant" },
              ],
            },
            {
              label: "Fusion Strategies",
              children: [
                { label: "Early Fusion: raw data (e.g., LiDAR â†’ images)" },
                { label: "Mid Fusion: feature maps from neural networks" },
                { label: "Late Fusion: final bounding boxes/predictions" },
              ],
            },
          ],
        },
        {
          label: "Visual Odometry (VO) & SLAM",
          children: [
            { label: "Estimate ego-motion from sequential images" },
            { label: "Map the environment simultaneously" },
            {
              label: "Key Concepts",
              children: [
                { label: "Feature extraction/matching (SIFT, ORB)" },
                { label: "Epipolar Geometry" },
                { label: "Essential vs. Fundamental matrices" },
                { label: "Bundle Adjustment" },
              ],
            },
          ],
        },
        {
          label: "Optical Flow & Scene Flow",
          children: [
            { label: "Pixel-level or point-level motion estimation" },
            { label: "Between consecutive frames" },
            { label: "Evaluation: End-Point Error (EPE)" },
          ],
        },
      ],
    },
    {
      label: "Modern Representation & Multimodal Learning",
      children: [
        {
          label: "Self-Supervised Representation Learning",
          children: [
            {
              label: "Contrastive Learning (SimCLR)",
              children: [
                { label: "Pulls augmented views of same image together" },
                { label: "Pushes different images apart" },
                { label: "In latent space" },
              ],
            },
            {
              label: "Masked Image Modeling (MAE)",
              children: [
                { label: "Masks high percentage of image" },
                { label: "Trains autoencoder to reconstruct missing patches" },
              ],
            },
          ],
        },
        {
          label: "Vision & Language",
          children: [
            {
              label: "Image Captioning",
              children: [
                { label: "Encoder-Decoder architecture" },
                { label: "CNN/ViT encodes image" },
                { label: "RNN/Transformer generates text autoregressively" },
              ],
            },
            {
              label: "Large Vision Models (LVMs) & VQA",
              children: [
                { label: "Fusing visual tokens with LLMs" },
                { label: "Via cross-attention or linear projection layers" },
                { label: "Answer questions about visual content" },
              ],
            },
            {
              label: "Vision-Language Models (VLMs)",
              children: [
                {
                  label: "Contrastive Learning (e.g., CLIP)",
                  children: [
                    { label: "Maximize cosine similarity for matching pairs" },
                    { label: "Minimize similarity for incorrect pairs" },
                    { label: "Within-batch negative sampling" },
                  ],
                },
                {
                  label: "Generative VLMs (e.g., LLaVA, BLIP)",
                  children: [
                    { label: "Frozen image encoder (e.g., CLIP ViT)" },
                    { label: "Connected to LLM decoder via projection layer" },
                    { label: "Visual reasoning & question answering" },
                  ],
                },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Implementation & Optimization",
      children: [
        {
          label: "Distributed Training",
          children: [
            {
              label: "DDP (Distributed Data Parallel)",
              children: [
                { label: "Replicate model on every GPU" },
                { label: "Split batch across GPUs" },
                { label: "Best for models fitting on single GPU" },
              ],
            },
            {
              label: "FSDP (Fully Sharded Data Parallel)",
              children: [
                { label: "Shard parameters, gradients, optimizer states" },
                { label: "Across multiple GPUs" },
                { label: "Crucial for massive models (VLMs)" },
              ],
            },
          ],
        },
        {
          label: "Deployment & Edge Optimization",
          children: [
            {
              label: "Quantization",
              children: [
                { label: "FP32 â†’ INT8 or FP16" },
                { label: "Reduce memory footprint & latency" },
                { label: "Post-Training Quantization (PTQ)" },
                { label: "Quantization-Aware Training (QAT)" },
              ],
            },
            {
              label: "TensorRT / ONNX",
              children: [
                { label: "Export PyTorch â†’ optimized execution graph" },
                { label: "Low-latency inference on target hardware" },
              ],
            },
            {
              label: "FlashAttention",
              children: [
                { label: "Hardware-aware optimization" },
                { label: "Speeds up transformer attention layers" },
                { label: "Reduces GPU HBM memory reads/writes" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Loss Functions & Evaluation Metrics",
      children: [
        {
          label: "Detection Metrics",
          children: [
            {
              label: "Intersection over Union (IoU)",
              children: [
                { label: "IoU = Area of Overlap / Area of Union" },
              ],
            },
            {
              label: "mean Average Precision (mAP)",
              children: [
                { label: "Area under Precision-Recall curve" },
                { label: "Averaged across all classes" },
                { label: "Various IoU thresholds" },
              ],
            },
            {
              label: "NuScenes Detection Score (NDS)",
              children: [
                { label: "Composite metric combining mAP" },
                { label: "Errors in: translation, scale, orientation" },
                { label: "Velocity & attributes" },
              ],
            },
          ],
        },
        {
          label: "Loss Functions",
          children: [
            {
              label: "Focal Loss",
              children: [
                { label: "Addresses severe class imbalance" },
                { label: "Down-weights well-classified examples" },
                { label: "FL(p_t) = -Î±_t(1 - p_t)^Î³ log(p_t)" },
              ],
            },
            {
              label: "InfoNCE / Contrastive Loss",
              children: [
                { label: "Self-supervised learning & VLMs" },
                { label: "Pull positive pairs together" },
                { label: "Push negative pairs apart" },
                { label: "In latent space" },
              ],
            },
          ],
        },
      ],
    },
    {
      label: "Data Engines & MLOps",
      children: [
        {
          label: "Active Learning",
          children: [
            { label: "Intelligently sample informative unlabelled data" },
            { label: "Send for human annotation" },
            {
              label: "Sampling Strategies",
              children: [
                { label: "Highest model uncertainty" },
                { label: "Highest entropy" },
                { label: "Greatest ensemble disagreement" },
              ],
            },
          ],
        },
        {
          label: "Handling the Long Tail",
          children: [
            { label: "Oversampling minority classes" },
            {
              label: "Synthetic Data Generation",
              children: [
                { label: "Via simulation" },
                { label: "Via diffusion models" },
              ],
            },
            {
              label: "Decoupled Training",
              children: [
                { label: "Freeze backbone representation" },
                { label: "Retrain classifier head only" },
              ],
            },
          ],
        },
      ],
    },
  ],
};

const pythonInterviewData = {
  root: "ðŸ”¹ Python Interview",
  children: [
    {
      label: "Priority Queues / heapq",
      children: [
        {
          label: "Min-Heap (Default)",
          children: [
            { label: "heapq.heapify(heap) â†’ O(n) in-place" },
            { label: "heapq.heappush(heap, val) â†’ O(log n)" },
            { label: "heapq.heappop(heap) â†’ O(log n)" },
            { label: "heap[0] â†’ peek smallest (O(1))" },
          ],
        },
        {
          label: "Max-Heap Trick",
          children: [
            { label: "Negate values: push -val, pop -heapq.heappop()" },
            { label: "Most common interview hack" },
          ],
        },
        {
          label: "Tuple Heap",
          children: [
            { label: "Compares first element, then second" },
            { label: "heapq.heappush(heap, (priority, index, value))" },
            { label: "For max-heap: negate priority only" },
          ],
        },
        {
          label: "K Largest/Smallest Patterns",
          children: [
            { label: "K largest â†’ min-heap of size K" },
            { label: "Keep popping small ones" },
            { label: "heapq.heapreplace(heap, num) â†’ pop + push" },
          ],
        },
        {
          label: "Merge K Sorted Lists",
          children: [
            { label: "Push (val, list_idx, elem_idx)" },
            { label: "Classic interview problem" },
          ],
        },
        {
          label: "Gotchas",
          children: [
            { label: "heapify() is O(n), not O(n log n)" },
            { label: "No built-in decrease-key" },
            { label: "Use set + lazy delete pattern" },
          ],
        },
      ],
    },
    {
      label: "Dynamic Programming",
      children: [
        {
          label: "@lru_cache (Fastest)",
          children: [
            { label: "from functools import lru_cache" },
            { label: "@lru_cache(maxsize=None)" },
            { label: "Clean & fast for interviews" },
          ],
        },
        {
          label: "Manual Dict Memo",
          children: [
            { label: "Shows understanding of memoization" },
            { label: "Use tuple keys for multi-state" },
          ],
        },
        {
          label: "2D Memo",
          children: [
            { label: "Use tuple keys: memo[(m, n)]" },
            { label: "Very common pattern" },
          ],
        },
        {
          label: "Space Optimization",
          children: [
            { label: "0/1 Knapsack â†’ O(W) space" },
            { label: "Reverse loop prevents using same item twice" },
            { label: "for w in range(W, wt-1, -1)" },
          ],
        },
        {
          label: "House Robber Pattern",
          children: [
            { label: "Two variables only: prev2, prev1" },
            { label: "Max non-adjacent sum" },
          ],
        },
        {
          label: "Digit DP Template",
          children: [
            { label: "For 'how many numbers between A and B'" },
            { label: "State: (index, is_less, is_started, ...)" },
          ],
        },
        {
          label: "Rolling Array",
          children: [
            { label: "If dp[i] only depends on dp[i-1]" },
            { label: "Use two rows or single array" },
          ],
        },
      ],
    },
    {
      label: "Sorting & Advanced Patterns",
      children: [
        {
          label: "Stable Sort",
          children: [
            { label: "Python's sorted() is stable" },
            { label: "Preserves original order on ties" },
          ],
        },
        {
          label: "Multi-Key Sort",
          children: [
            { label: "sorted(items, key=lambda x: (x[0], -x[1]))" },
            { label: "Earliest deadline, then max profit" },
          ],
        },
        {
          label: "Custom Distance Sort",
          children: [
            { label: "sorted(points, key=lambda p: p[0]**2 + p[1]**2)" },
          ],
        },
        {
          label: "Dutch National Flag",
          children: [
            { label: "3-way partition (red < pivot < blue)" },
            { label: "lo = mid = 0; hi = len(nums)-1" },
            { label: "Sort colors problem" },
          ],
        },
      ],
    },
    {
      label: "Bitwise Operations",
      children: [
        {
          label: "Power of 2",
          children: [
            { label: "n > 0 and n & (n-1) == 0" },
          ],
        },
        {
          label: "Odd/Even",
          children: [
            { label: "n & 1" },
          ],
        },
        {
          label: "Last Set Bit",
          children: [
            { label: "n & -n (two's complement trick)" },
          ],
        },
        {
          label: "Count Set Bits",
          children: [
            { label: "Brian Kernighan: while n: n &= n-1; count += 1" },
            { label: "O(set bits) complexity" },
          ],
        },
        {
          label: "Bit Manipulation",
          children: [
            { label: "Set k-th bit: n | (1 << k)" },
            { label: "Clear k-th bit: n & ~(1 << k)" },
            { label: "Toggle k-th bit: n ^ (1 << k)" },
            { label: "Get k-th bit: (n >> k) & 1" },
          ],
        },
        {
          label: "XOR Tricks",
          children: [
            { label: "Swap: a ^= b; b ^= a; a ^= b" },
            { label: "Missing number: xor all nums, then xor 1..n" },
            { label: "Single Number III: find rightmost set bit" },
          ],
        },
        {
          label: "Bitmask DP",
          children: [
            { label: "State as integer (subsets, digit DP)" },
            { label: "Iterate over all subsets: for mask in range(1 << n)" },
          ],
        },
      ],
    },
    {
      label: "Advanced Data Structures",
      children: [
        {
          label: "deque",
          children: [
            { label: "appendleft() & popleft() are O(1)" },
            { label: "list.pop(0) is O(n)" },
            { label: "Sliding windows, BFS" },
          ],
        },
        {
          label: "Counter",
          children: [
            { label: "c1 & c2 (intersection)" },
            { label: "c1 - c2 (find differences)" },
            { label: "c.most_common(k)" },
          ],
        },
        {
          label: "bisect",
          children: [
            { label: "Binary search on sorted arrays" },
            { label: "bisect_right, bisect_left" },
            { label: "Find insertion point to maintain order" },
          ],
        },
        {
          label: "defaultdict",
          children: [
            { label: "Group by key in one line" },
            { label: "groups = defaultdict(list)" },
          ],
        },
      ],
    },
    {
      label: "Monotonic Stack/Queue",
      children: [
        {
          label: "Monotonic Increasing Stack",
          children: [
            { label: "Next Greater Element" },
            { label: "Largest Rectangle in Histogram" },
            { label: "Each element pushed/popped once â†’ O(n)" },
          ],
        },
        {
          label: "Sliding Window Maximum",
          children: [
            { label: "Use deque to maintain decreasing order" },
            { label: "Remove out-of-window elements" },
            { label: "O(n) complexity" },
          ],
        },
      ],
    },
    {
      label: "Prefix Sum & Difference Array",
      children: [
        {
          label: "Prefix Sum",
          children: [
            { label: "prefix = [0]; for num in nums: prefix.append(prefix[-1] + num)" },
            { label: "Range sum: prefix[r] - prefix[l]" },
          ],
        },
        {
          label: "Difference Array",
          children: [
            { label: "Range update trick" },
            { label: "diff[l] += val; diff[r+1] -= val" },
            { label: "O(n + q) instead of O(n*q)" },
          ],
        },
      ],
    },
    {
      label: "Binary Search Patterns",
      children: [
        {
          label: "Lower Bound Template",
          children: [
            { label: "Find first position >= target" },
            { label: "l, r = 0, len(nums); while l < r" },
          ],
        },
        {
          label: "Binary Search on Answer",
          children: [
            { label: "Minimize maximum / Maximize minimum" },
            { label: "Koko Eating Bananas pattern" },
            { label: "Think in terms of monotonic property" },
          ],
        },
      ],
    },
    {
      label: "Graph Patterns",
      children: [
        {
          label: "BFS Template",
          children: [
            { label: "from collections import deque" },
            { label: "q = deque([start]); visited = {start}" },
            { label: "Standard template" },
          ],
        },
        {
          label: "DFS Iterative",
          children: [
            { label: "Safer than recursion in deep graphs" },
            { label: "stack = [start]; visited = set()" },
          ],
        },
      ],
    },
    {
      label: "Python Gotchas & Syntax",
      children: [
        {
          label: "Mutable Default Arguments",
          children: [
            { label: "def bad(x, lst=[]): â† created ONCE" },
            { label: "Fix: def good(x, lst=None): lst = lst or []" },
          ],
        },
        {
          label: "List Multiplication",
          children: [
            { label: "[[0]*5]*4 â†’ all rows are SAME list!" },
            { label: "Fix: [[0]*5 for _ in range(4)]" },
          ],
        },
        {
          label: "is vs ==",
          children: [
            { label: "Use == for value, is for identity" },
            { label: "is for None, True/False, singletons" },
            { label: "Small ints cached (256), but not 257" },
          ],
        },
        {
          label: "Walrus Operator (:=)",
          children: [
            { label: "if match := pattern.search(data):" },
            { label: "while (line := file.readline()):" },
            { label: "Python 3.8+" },
          ],
        },
        {
          label: "String Operations",
          children: [
            { label: "Never: s += char in loop (O(nÂ²))" },
            { label: "Always: collect in list, then ''.join()" },
            { label: "Reverse: A[::-1], Copy: A[:]" },
          ],
        },
        {
          label: "Late Binding Closures",
          children: [
            { label: "funcs = [lambda x: x*i for i in range(4)]" },
            { label: "Fix: lambda x, i=i: x*i" },
          ],
        },
      ],
    },
    {
      label: "Performance Optimizations",
      children: [
        {
          label: "Complexity Micro-Optimizations",
          children: [
            { label: "if x in list â†’ use set" },
            { label: "list.pop(0) â†’ deque.popleft()" },
            { label: "+= string loop â†’ ''.join()" },
            { label: "nested loops for freq â†’ Counter" },
            { label: "manual heap build â†’ heapify()" },
          ],
        },
        {
          label: "Matrix Operations",
          children: [
            { label: "Transpose: list(zip(*matrix))" },
            { label: "Flatten: [x for row in matrix for x in row]" },
          ],
        },
      ],
    },
    {
      label: "Math Tricks",
      children: [
        {
          label: "Ceil Division",
          children: [
            { label: "ceil = (a + b - 1) // b" },
          ],
        },
        {
          label: "Modular Exponentiation",
          children: [
            { label: "pow(base, exp, mod) â†’ O(log n)" },
          ],
        },
        {
          label: "GCD / LCM",
          children: [
            { label: "from math import gcd" },
            { label: "lcm = a * b // gcd(a, b)" },
          ],
        },
      ],
    },
    {
      label: "Common Patterns",
      children: [
        {
          label: "Kadane's Algorithm",
          children: [
            { label: "Maximum subarray sum" },
            { label: "best = curr = nums[0]" },
            { label: "curr = max(n, curr + n)" },
          ],
        },
        {
          label: "Check if Sorted",
          children: [
            { label: "all(a <= b for a, b in zip(nums, nums[1:]))" },
            { label: "Or: all(a <= b for a, b in pairwise(nums))" },
          ],
        },
        {
          label: "Unique Elements (Ordered)",
          children: [
            { label: "list(dict.fromkeys(lst))" },
            { label: "Python 3.7+ dict keys ordered" },
          ],
        },
      ],
    },
    {
      label: "Edge Cases to Consider",
      children: [
        { label: "Empty input" },
        { label: "Single element" },
        { label: "Large constraints (10^5 / 10^6)" },
        { label: "Negative numbers in prefix sums" },
        { label: "Duplicate handling" },
        { label: "Always ask about constraints" },
      ],
    },
  ],
};

// Map cheatsheet IDs to their data
const mindmapDataMap: Record<string, any> = {
  "intro-to-ml": introToMLData,
  "data-evaluation": dataEvaluationData,
  "classical-supervised": classicalSupervisedData,
  "stats-learning-theory": statsLearningTheoryData,
  "advanced-classical": advancedClassicalData,
  "ensemble-methods": ensembleMethodsData,
  "tree-based-ml": treeBasedMLData,
  "optimization-ml": optimizationMLData,
  "modern-deep-learning": modernDeepLearningData,
  "unsupervised-learning": unsupervisedLearningData,
  "probabilistic-graphical": probabilisticGraphicalData,
  "modern-topics": modernTopicsData,
  "interpretability-fairness": interpretabilityFairnessData,
  "scaling-production": scalingProductionData,
  "project-research-skills": projectResearchSkillsData,
  "computer-vision": computerVisionData,
  "python-interview": pythonInterviewData,
};
---

<Layout title={`ML Cheatsheets | ${SITE.title}`}>
  <Header />
  <Main pageTitle="ML Cheatsheets" pageDesc="Visual mindmaps for machine learning concepts - Complete ML course coverage">
    <div class="space-y-12">
      <!-- Navigation for cheatsheets -->
      <div class="grid gap-4 sm:grid-cols-2 lg:grid-cols-3">
        {cheatsheets.map((cheatsheet) => (
          <a
            href={`#${cheatsheet.id}`}
            class="group relative overflow-hidden rounded-2xl border border-white/40 bg-white/70 p-6 shadow-lg backdrop-blur-sm transition-all hover:border-accent/60 hover:shadow-xl hover:-translate-y-1 dark:border-slate-700/40 dark:bg-slate-900/70"
          >
            <div class="absolute inset-0 -z-10 bg-gradient-to-br from-accent/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100" />
            <h2 class="text-xl font-semibold text-foreground group-hover:text-accent transition-colors">
              {cheatsheet.title}
            </h2>
            <p class="mt-2 text-sm text-secondary-foreground">
              {cheatsheet.description}
            </p>
          </a>
        ))}
      </div>

      <!-- All Cheatsheet Sections -->
      {cheatsheets.map((cheatsheet) => (
        <section id={cheatsheet.id} class="scroll-mt-24">
          <div class="mb-6">
            <h2 class="text-2xl font-semibold text-foreground">
              {cheatsheet.title}
            </h2>
            <p class="mt-2 text-sm text-secondary-foreground">
              {cheatsheet.description}
            </p>
          </div>
          <div class="overflow-x-auto rounded-2xl border border-white/40 bg-white/50 p-6 shadow-lg backdrop-blur-sm dark:border-slate-700/40 dark:bg-slate-900/50">
            <Mindmap data={mindmapDataMap[cheatsheet.id]} />
          </div>
        </section>
      ))}
    </div>
  </Main>
  <Footer />
</Layout>
